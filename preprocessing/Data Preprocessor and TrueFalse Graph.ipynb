{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97aee939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackml.dataset # https://github.com/LAL/trackml-library \n",
    "\n",
    "from datasets.graph_utils import Graph, save_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a72cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dphi(phi1, phi2):\n",
    "    \"\"\"Computes phi2-phi1 given in range [-pi,pi]\"\"\"\n",
    "    dphi = phi2 - phi1\n",
    "    dphi[dphi > np.pi] -= 2*np.pi\n",
    "    dphi[dphi < -np.pi] += 2*np.pi\n",
    "    return dphi\n",
    "\n",
    "def calc_eta(r, z):\n",
    "    theta = np.arctan2(r, z)\n",
    "    return -1. * np.log(np.tan(theta / 2.))\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, evtid, vlids, pt_min, phi_slope_max, z0_max, n_phi_sections, n_eta_sections, eta_range, phi_range):\n",
    "        # load_event('/Users/Eden/Desktop/Datasets/train_100_events/event000001000-hits')\n",
    "        # The original preprocessing module only uses hits data.\n",
    "        self.evtid = evtid\n",
    "        self.hits, self.particles, self.truth = trackml.dataset.load_event(evtid, parts=['hits', 'particles', 'truth'])\n",
    "        self.vlids  = vlids\n",
    "        self.pt_min = pt_min\n",
    "        self.phi_slope_max = phi_slope_max\n",
    "        self.z0_max = z0_max\n",
    "        self.n_phi_sections = n_phi_sections\n",
    "        self.n_eta_sections = n_eta_sections\n",
    "        self.eta_range = eta_range\n",
    "        self.phi_range = phi_range\n",
    "        \n",
    "    def select_segments(self, hits1, hits2):\n",
    "        \"\"\"\n",
    "        Construct a list of selected segments from the pairings\n",
    "        between hits1 and hits2, filtered with the specified\n",
    "        phi slope and z0 criteria.\n",
    "        Returns: pd DataFrame of (index_1, index_2), corresponding to the\n",
    "        DataFrame hit label-indices in hits1 and hits2, respectively.\n",
    "        \"\"\"\n",
    "        # Start with all possible pairs of hits\n",
    "        keys = ['evtid', 'r', 'phi', 'z']\n",
    "        hit_pairs = hits1[keys].reset_index().merge(\n",
    "            hits2[keys].reset_index(), on='evtid', suffixes=('_1', '_2'))\n",
    "        # Compute line through the points\n",
    "        dphi = calc_dphi(hit_pairs.phi_1, hit_pairs.phi_2)\n",
    "        dz = hit_pairs.z_2 - hit_pairs.z_1\n",
    "        dr = hit_pairs.r_2 - hit_pairs.r_1\n",
    "        phi_slope = dphi / dr\n",
    "        z0 = hit_pairs.z_1 - hit_pairs.r_1 * dz / dr\n",
    "        # Filter segments according to criteria\n",
    "        good_seg_mask = (phi_slope.abs() < self.phi_slope_max) & (z0.abs() < self.z0_max)\n",
    "        return hit_pairs[['index_1', 'index_2']][good_seg_mask]\n",
    "    \n",
    "    def construct_graph(self, hits, layer_pairs, feature_names, feature_scale):\n",
    "        \"\"\"Construct one graph (e.g. from one event)\"\"\"\n",
    "        # Loop over layer pairs and construct segments\n",
    "        layer_groups = hits.groupby('layer')\n",
    "        segments = []\n",
    "        for (layer1, layer2) in layer_pairs:\n",
    "            # Find and join all hit pairs\n",
    "            try:\n",
    "                hits1 = layer_groups.get_group(layer1)\n",
    "                hits2 = layer_groups.get_group(layer2)\n",
    "            # If an event has no hits on a layer, we get a KeyError.\n",
    "            # In that case we just skip to the next layer pair\n",
    "            except KeyError as e:\n",
    "                logging.info('skipping empty layer: %s' % e)\n",
    "                continue\n",
    "            # Construct the segments\n",
    "            segments.append(self.select_segments(hits1, hits2))\n",
    "        # Combine segments from all layer pairs\n",
    "        segments = pd.concat(segments)\n",
    "    \n",
    "        # Prepare the graph matrices\n",
    "        n_hits = hits.shape[0]\n",
    "        n_edges = segments.shape[0]\n",
    "        X = (hits[feature_names].values / feature_scale).astype(np.float32)\n",
    "        Ri = np.zeros((n_hits, n_edges), dtype=np.uint8)\n",
    "        Ro = np.zeros((n_hits, n_edges), dtype=np.uint8)\n",
    "        y = np.zeros(n_edges, dtype=np.float32)\n",
    "    \n",
    "        # We have the segments' hits given by dataframe label,\n",
    "        # so we need to translate into positional indices.\n",
    "        # Use a series to map hit label-index onto positional-index.\n",
    "        hit_idx = pd.Series(np.arange(n_hits), index=hits.index)\n",
    "        seg_start = hit_idx.loc[segments.index_1].values\n",
    "        seg_end = hit_idx.loc[segments.index_2].values\n",
    "    \n",
    "        # Now we can fill the association matrices.\n",
    "        # Note that Ri maps hits onto their incoming edges,\n",
    "        # which are actually segment endings.\n",
    "        Ri[seg_end, np.arange(n_edges)] = 1\n",
    "        Ro[seg_start, np.arange(n_edges)] = 1\n",
    "        # Fill the segment labels\n",
    "        pid1 = hits.particle_id.loc[segments.index_1].values\n",
    "        pid2 = hits.particle_id.loc[segments.index_2].values\n",
    "        y[:] = (pid1 == pid2)\n",
    "        # Return a tuple of the results\n",
    "        return Graph(X, Ri, Ro, y)\n",
    "\n",
    "    def select_hits(self, hits, truth, particles):\n",
    "        # Barrel volume and layer ids\n",
    "        n_det_layers = len(self.vlids)\n",
    "        # Select barrel layers and assign convenient layer number [0-9]\n",
    "        vlid_groups = hits.groupby(['volume_id', 'layer_id'])\n",
    "        hits = pd.concat([vlid_groups.get_group(self.vlids[i]).assign(layer=i)\n",
    "                          for i in range(n_det_layers)])\n",
    "        # Calculate particle transverse momentum\n",
    "        pt = np.sqrt(particles.px**2 + particles.py**2)\n",
    "        # True particle selection.\n",
    "        # Applies pt cut, removes all noise hits.\n",
    "        particles = particles[pt > self.pt_min]\n",
    "        truth = (truth[['hit_id', 'particle_id']]\n",
    "                 .merge(particles[['particle_id']], on='particle_id'))\n",
    "        # Calculate derived hits variables\n",
    "        r = np.sqrt(hits.x**2 + hits.y**2)\n",
    "        phi = np.arctan2(hits.y, hits.x)\n",
    "        # Select the data columns we need\n",
    "        hits = (hits[['hit_id', 'z', 'layer']]\n",
    "                .assign(r=r, phi=phi)\n",
    "                .merge(truth[['hit_id', 'particle_id']], on='hit_id'))\n",
    "        # Remove duplicate hits. Needs work, original version doesn't work.\n",
    "        #hits = hits.loc[\n",
    "        #    hits.groupby(['particle_id', 'layer'], as_index=False).r.idxmin()]\n",
    "        return hits\n",
    "    def split_detector_sections(self, hits, phi_edges, eta_edges):\n",
    "        \"\"\"Split hits according to provided phi and eta boundaries.\"\"\"\n",
    "        hits_sections = []\n",
    "        # Loop over sections\n",
    "        for i in range(len(phi_edges) - 1):\n",
    "            phi_min, phi_max = phi_edges[i], phi_edges[i+1]\n",
    "            # Select hits in this phi section\n",
    "            phi_hits = hits[(hits.phi > phi_min) & (hits.phi < phi_max)]\n",
    "            # Center these hits on phi=0\n",
    "            centered_phi = phi_hits.phi - (phi_min + phi_max) / 2\n",
    "            phi_hits = phi_hits.assign(phi=centered_phi, phi_section=i)\n",
    "            for j in range(len(eta_edges) - 1):\n",
    "                eta_min, eta_max = eta_edges[j], eta_edges[j+1]\n",
    "                # Select hits in this eta section\n",
    "                eta = calc_eta(phi_hits.r, phi_hits.z)\n",
    "                sec_hits = phi_hits[(eta > eta_min) & (eta < eta_max)]\n",
    "                hits_sections.append(sec_hits.assign(eta_section=j))\n",
    "        return hits_sections\n",
    "    def process_event(self):\n",
    "        hits = self.select_hits(self.hits, self.truth, self.particles).assign(evtid=int(self.evtid[-9:]))\n",
    "    \n",
    "        # Divide detector into sections\n",
    "        phi_edges = np.linspace(*self.phi_range, num=self.n_phi_sections+1)\n",
    "        eta_edges = np.linspace(*self.eta_range, num=self.n_eta_sections+1)\n",
    "        hits_sections = self.split_detector_sections(hits, phi_edges, eta_edges)\n",
    "    \n",
    "        # Graph features and scale\n",
    "        feature_names = ['r', 'phi', 'z']\n",
    "        feature_scale = np.array([1000., np.pi / self.n_phi_sections, 1000.])\n",
    "    \n",
    "#       # Define adjacent layers\n",
    "        n_det_layers = 10\n",
    "        l = np.arange(n_det_layers)\n",
    "        layer_pairs = np.stack([l[:-1], l[1:]], axis=1)\n",
    "    \n",
    "#       # Construct the graph\n",
    "        graphs = [self.construct_graph(section_hits, layer_pairs=layer_pairs, \n",
    "                                  feature_names=feature_names, feature_scale=feature_scale) \n",
    "                                  for section_hits in hits_sections]\n",
    "        return graphs\n",
    "#         # Write these graphs to the output directory\n",
    "#         try:\n",
    "#             base_prefix = os.path.basename(prefix)\n",
    "#             filenames = [os.path.join(output_dir, '%s_g%03i' % (base_prefix, i))\n",
    "#                          for i in range(len(graphs))]\n",
    "#         except Exception as e:\n",
    "#             logging.info(e)\n",
    "#         logging.info('Event %i, writing graphs', evtid)\n",
    "#         save_graphs(graphs, filenames)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ce1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base values\n",
    "#    pt_min: 0. # GeV\n",
    "#    phi_slope_max: 0.0006\n",
    "#    z0_max: 200 # *inconsistent with the paper should be 100\n",
    "#    n_phi_sections: 8\n",
    "#    n_eta_sections: 2\n",
    "#    eta_range: [-5, 5]\n",
    "#    phi_range=(-np.pi, np.pi)\n",
    "\n",
    "evtstr = '/Users/Eden/Desktop/Datasets/train_100_events/event000001000' \n",
    "#Need to Iterate through every event, the script will automatically pull the -hits.csv\n",
    "\n",
    "#volume_id: numerical identifier of the detector group.\n",
    "#layer_id: numerical identifier of the detector layer inside the group.\n",
    "#module_id: numerical identifier of the detector module inside the layer.\n",
    "\n",
    "# Barrel volume and layer ids\n",
    "vlids_original = [(8,2), (8,4), (8,6), (8,8),\n",
    "                  (13,2), (13,4), (13,6), (13,8),\n",
    "                  (17,2), (17,4)]\n",
    "# Radius 400, TODO: Figure out the right volume and layer combo\n",
    "vlids_400 = [()]\n",
    "\n",
    "vlids = vlids_original\n",
    "\n",
    "pt_min = 0\n",
    "phi_slope_max = 0.0006 \n",
    "z0_max = 200 \n",
    "n_phi_sections = 8 \n",
    "n_eta_sections = 2\n",
    "eta_range = [-5,5]\n",
    "phi_range = (-np.pi, np.pi)\n",
    "\n",
    "\n",
    "preproc = Preprocessor(evtid=evtstr, vlids=vlids, pt_min=pt_min, phi_slope_max=phi_slope_max, \n",
    "                       z0_max=z0_max, n_phi_sections=n_phi_sections, n_eta_sections=n_eta_sections, \n",
    "                       eta_range=eta_range, phi_range=phi_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381433aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = preproc.process_event() #Generated 16 graphs on the first event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fe9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time, datetime, csv\n",
    "sys.path.append(os.path.abspath(os.path.join('.')))\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tools import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ee616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_section = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a03410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cylindrical(graphs,n_section):\n",
    "\n",
    "        #print('Plotting file: ' + filenames[0] + ' to: ' + pdf_dir)\n",
    "        X, Ri, Ro, y = graphs[0]\n",
    "\n",
    "        feats_o = X[np.where(Ri.T)[1]]\n",
    "        feats_i = X[np.where(Ro.T)[1]]\n",
    "        \n",
    "        feats_o[:,0] = feats_o[:,0]*1000 \n",
    "        feats_o[:,1] = feats_o[:,1]*np.pi/n_section\n",
    "        feats_o[:,2] = feats_o[:,2]*1000  \n",
    "        feats_i[:,0] = feats_i[:,0]*1000  \n",
    "        feats_i[:,1] = feats_i[:,1]*np.pi/n_section\n",
    "        feats_i[:,2] = feats_i[:,2]*1000  \n",
    "\n",
    "        print('Plotting: Initial Graph colored in Cylindrical coordinates!')\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (10,5),sharey=True, tight_layout=True)\n",
    "        cmap = plt.get_cmap('bwr_r')\n",
    "        color = {0:'red',1:'blue'}\n",
    "\n",
    "        ax[0].scatter((np.pi/8)*X[:,1], 1000*X[:,0], c='k')\n",
    "        for j in range(y.shape[0]):\n",
    "            seg_args = dict(c=color[int(y[j])], alpha=1.)\n",
    "            ax[0].plot([feats_o[j,1],feats_i[j,1]],[feats_o[j,0],feats_i[j,0]], '-', **seg_args)\n",
    "        ax[0].set_ylabel('r [mm]')\n",
    "        ax[0].set_xlabel(r'$\\phi$'+' [rad]')\n",
    "    \n",
    "        ax[1].scatter(1000*X[:,2], 1000*X[:,0], c='k')\n",
    "        for j in range(y.shape[0]):\n",
    "            seg_args = dict(c=color[int(y[j])], alpha=1.)\n",
    "            ax[1].plot([feats_o[j,2],feats_i[j,2]],[feats_o[j,0],feats_i[j,0]], '-', **seg_args)\n",
    "        ax[1].set_ylabel('r [mm]')\n",
    "        ax[1].set_xlabel('z [mm]')\n",
    "    \n",
    "        # create custom legend\n",
    "        legend_elements = [Line2D([0], [0], color='red', label='fake'),\n",
    "            Line2D([0], [0], color='blue', label='true')]\n",
    "\n",
    "        ax[0].legend(handles=legend_elements)\n",
    "        ax[1].legend(handles=legend_elements)\n",
    "\n",
    "        plt.savefig(pdf_dir+'Cylindrical_initial_graph_colored.pdf')\n",
    "        plt.savefig(png_dir+'Cylindrical_initial_graph_colored.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49742cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting: Initial Graph colored in Cylindrical coordinates!\n"
     ]
    }
   ],
   "source": [
    "plot_cylindrical(graphs, n_section=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d745e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
